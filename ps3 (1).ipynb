{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Set 3: Neural Networks\n",
    "\n",
    "### Overview\n",
    "In this problem set, you'll explore the foundational concepts of neural networks, covering basic architecture, activation functions, forward propagation, regularization, and adaptive learning. You'll also complete coding exercises to implement neural network components and train a basic neural network. You will both complete this Python script (`ps3.ipynb`) and submit a LaTeX report (`ps3.tex` and `ps3.pdf`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Architecture of a Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A neural network is composed of layers of neurons: input layer, hidden layer(s), and an output layer. Each neuron receives inputs, processes them, and passes the result to the next layer.\n",
    "\n",
    "In this section, you'll implement a basic 3-layer neural network structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output after forward propagation:\n",
      "[[0.49548103]\n",
      " [0.52211112]\n",
      " [0.54861611]]\n",
      "Loss: 0.2582862899438419\n",
      "Output after one training step:\n",
      "[[0.48497748]\n",
      " [0.50800092]\n",
      " [0.53099047]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sigmoid activation function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Derivative of Sigmoid\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "# ReLU activation function\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "# Derivative of ReLU\n",
    "def relu_derivative(x):\n",
    "    return np.where(x > 0, 1, 0)\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        # Initialize weights and biases\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        # Weights and biases for each layer\n",
    "        self.weights_input_hidden = np.random.randn(self.input_size, self.hidden_size)  # Input to Hidden layer\n",
    "        self.bias_hidden = np.zeros((1, self.hidden_size))\n",
    "        \n",
    "        self.weights_hidden_output = np.random.randn(self.hidden_size, self.output_size)  # Hidden to Output layer\n",
    "        self.bias_output = np.zeros((1, self.output_size))\n",
    "        \n",
    "    def forward(self, X):\n",
    "        # Forward propagation\n",
    "        self.hidden_input = np.dot(X, self.weights_input_hidden) + self.bias_hidden\n",
    "        self.hidden_output = relu(self.hidden_input)  # Hidden layer activation\n",
    "        \n",
    "        self.output_input = np.dot(self.hidden_output, self.weights_hidden_output) + self.bias_output\n",
    "        self.output = sigmoid(self.output_input)  # Output layer activation (for binary classification)\n",
    "        \n",
    "        return self.output\n",
    "\n",
    "    def compute_loss(self, y_true, y_pred):\n",
    "        # Mean Squared Error loss function (for regression)\n",
    "        return np.mean((y_true - y_pred) ** 2)\n",
    "    \n",
    "    def backward(self, X, y_true, learning_rate=0.01):\n",
    "        # Backward propagation (Gradient Descent)\n",
    "        \n",
    "        # Output layer error and gradient\n",
    "        output_error = y_true - self.output\n",
    "        output_delta = output_error * sigmoid_derivative(self.output)\n",
    "        \n",
    "        # Hidden layer error and gradient\n",
    "        hidden_error = output_delta.dot(self.weights_hidden_output.T)\n",
    "        hidden_delta = hidden_error * relu_derivative(self.hidden_output)\n",
    "        \n",
    "        # Update weights and biases\n",
    "        self.weights_hidden_output += self.hidden_output.T.dot(output_delta) * learning_rate\n",
    "        self.bias_output += np.sum(output_delta, axis=0, keepdims=True) * learning_rate\n",
    "        \n",
    "        self.weights_input_hidden += X.T.dot(hidden_delta) * learning_rate\n",
    "        self.bias_hidden += np.sum(hidden_delta, axis=0, keepdims=True) * learning_rate\n",
    "\n",
    "# Example usage:\n",
    "input_size = 3  # Example: 3 input features\n",
    "hidden_size = 4  # Hidden layer with 4 neurons\n",
    "output_size = 1  # Output layer (1 neuron for binary classification)\n",
    "\n",
    "# Initialize the neural network\n",
    "nn = NeuralNetwork(input_size, hidden_size, output_size)\n",
    "\n",
    "# Example input data (X) and labels (y)\n",
    "X = np.array([[0.1, 0.2, 0.3],\n",
    "              [0.4, 0.5, 0.6],\n",
    "              [0.7, 0.8, 0.9]])\n",
    "y = np.array([[0], [1], [0]])\n",
    "\n",
    "# Forward propagation\n",
    "output = nn.forward(X)\n",
    "print(\"Output after forward propagation:\")\n",
    "print(output)\n",
    "\n",
    "# Compute loss\n",
    "loss = nn.compute_loss(y, output)\n",
    "print(f\"Loss: {loss}\")\n",
    "\n",
    "# Backpropagation (for a single training step)\n",
    "nn.backward(X, y, learning_rate=0.1)\n",
    "\n",
    "# Output after one training step\n",
    "output_after_training = nn.forward(X)\n",
    "print(\"Output after one training step:\")\n",
    "print(output_after_training)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Activation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Activation functions introduce non-linearity into the network, allowing it to learn more complex patterns. Common functions include:\n",
    "\n",
    "- **Sigmoid**: S-shaped curve, useful for binary classifications.\n",
    "- **ReLU (Rectified Linear Unit)**: Outputs zero if input is negative, otherwise outputs the input.\n",
    "- **Leaky ReLU**: Similar to ReLU but with a small gradient for negative inputs.\n",
    "\n",
    "### Exercise:\n",
    "Write functions for each activation function and plot them over a range of inputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sigmoid activation function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# ReLU activation function\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "# Leaky ReLU activation function\n",
    "def leaky_relu(x, alpha=0.01):\n",
    "    return np.where(x > 0, x, alpha * x)\n",
    "\n",
    "# Generate a range of inputs from -10 to 10\n",
    "x = np.linspace(-10, 10, 400)\n",
    "\n",
    "# Apply each activation function\n",
    "sigmoid_output = sigmoid(x)\n",
    "relu_output = relu(x)\n",
    "leaky_relu_output = leaky_relu(x)\n",
    "\n",
    "# Plotting the activation functions\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Sigmoid\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(x, sigmoid_output, label=\"Sigmoid\")\n",
    "plt.title(\"Sigmoid Activation\")\n",
    "plt.xlabel(\"Input\")\n",
    "plt.ylabel(\"Output\")\n",
    "plt.grid(True)\n",
    "\n",
    "# ReLU\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(x, relu_output, label=\"ReLU\", color='orange')\n",
    "plt.title(\"ReLU Activation\")\n",
    "plt.xlabel(\"Input\")\n",
    "plt.ylabel(\"Output\")\n",
    "plt.grid(True)\n",
    "\n",
    "# Leaky ReLU\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(x, leaky_relu_output, label=\"Leaky ReLU\", color='green')\n",
    "plt.title(\"Leaky ReLU Activation\")\n",
    "plt.xlabel(\"Input\")\n",
    "plt.ylabel(\"Output\")\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plots\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Forward Propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forward propagation is the process of passing inputs through the network to generate an output.\n",
    "\n",
    "### Exercise:\n",
    "Implement forward propagation for a 3-layer neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output after forward propagation:\n",
      "[[0.58485541]\n",
      " [0.68813456]\n",
      " [0.77574948]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Activation function: ReLU for the hidden layer, Sigmoid for the output layer\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        # Initialize weights and biases\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        # Weights and biases for each layer\n",
    "        self.weights_input_hidden = np.random.randn(self.input_size, self.hidden_size)  # Input to Hidden layer\n",
    "        self.bias_hidden = np.zeros((1, self.hidden_size))\n",
    "        \n",
    "        self.weights_hidden_output = np.random.randn(self.hidden_size, self.output_size)  # Hidden to Output layer\n",
    "        self.bias_output = np.zeros((1, self.output_size))\n",
    "\n",
    "    def forward(self, X):\n",
    "        # Forward propagation\n",
    "        \n",
    "        # Input to Hidden Layer\n",
    "        self.hidden_input = np.dot(X, self.weights_input_hidden) + self.bias_hidden\n",
    "        self.hidden_output = relu(self.hidden_input)  # Apply ReLU activation to hidden layer\n",
    "        \n",
    "        # Hidden to Output Layer\n",
    "        self.output_input = np.dot(self.hidden_output, self.weights_hidden_output) + self.bias_output\n",
    "        self.output = sigmoid(self.output_input)  # Apply Sigmoid activation to output layer\n",
    "        \n",
    "        return self.output\n",
    "\n",
    "# Example usage\n",
    "input_size = 3  # Example: 3 input features\n",
    "hidden_size = 4  # Hidden layer with 4 neurons\n",
    "output_size = 1  # Output layer (1 neuron for binary classification)\n",
    "\n",
    "# Initialize the neural network\n",
    "nn = NeuralNetwork(input_size, hidden_size, output_size)\n",
    "\n",
    "# Example input data (3 samples, each with 3 features)\n",
    "X = np.array([[0.1, 0.2, 0.3],\n",
    "              [0.4, 0.5, 0.6],\n",
    "              [0.7, 0.8, 0.9]])\n",
    "\n",
    "# Perform forward propagation\n",
    "output = nn.forward(X)\n",
    "print(\"Output after forward propagation:\")\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Overfitting and Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overfitting occurs when a model learns the noise in the training data rather than the actual pattern. Regularization helps control this.\n",
    "\n",
    "Common techniques include:\n",
    "\n",
    "- **L2 Regularization**: Adds a penalty based on the sum of squared weights.\n",
    "- **Dropout**: Randomly ignores some neurons during training.\n",
    "\n",
    "### Exercise:\n",
    "Implement L2 regularization in the loss calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output after forward propagation:\n",
      "[[0.51718437]\n",
      " [0.51138894]\n",
      " [0.50559044]]\n",
      "Loss with L2 regularization: 0.3482398896453753\n",
      "Output after one training step:\n",
      "[[0.51284954]\n",
      " [0.50666005]\n",
      " [0.50046852]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sigmoid activation function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# ReLU activation function\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size, lambda_reg=0.01):\n",
    "        # Initialize weights and biases\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.lambda_reg = lambda_reg  # Regularization strength\n",
    "        \n",
    "        # Weights and biases for each layer\n",
    "        self.weights_input_hidden = np.random.randn(self.input_size, self.hidden_size)  # Input to Hidden layer\n",
    "        self.bias_hidden = np.zeros((1, self.hidden_size))\n",
    "        \n",
    "        self.weights_hidden_output = np.random.randn(self.hidden_size, self.output_size)  # Hidden to Output layer\n",
    "        self.bias_output = np.zeros((1, self.output_size))\n",
    "\n",
    "    def forward(self, X):\n",
    "        # Forward propagation\n",
    "        \n",
    "        # Input to Hidden Layer\n",
    "        self.hidden_input = np.dot(X, self.weights_input_hidden) + self.bias_hidden\n",
    "        self.hidden_output = relu(self.hidden_input)  # Apply ReLU activation to hidden layer\n",
    "        \n",
    "        # Hidden to Output Layer\n",
    "        self.output_input = np.dot(self.hidden_output, self.weights_hidden_output) + self.bias_output\n",
    "        self.output = sigmoid(self.output_input)  # Apply Sigmoid activation to output layer\n",
    "        \n",
    "        return self.output\n",
    "\n",
    "    def compute_loss(self, y_true, y_pred):\n",
    "        # Mean Squared Error (MSE) loss\n",
    "        mse_loss = np.mean((y_true - y_pred) ** 2)\n",
    "        \n",
    "        # L2 Regularization term (sum of squared weights)\n",
    "        l2_loss = self.lambda_reg * (np.sum(self.weights_input_hidden ** 2) + np.sum(self.weights_hidden_output ** 2))\n",
    "        \n",
    "        # Total loss = MSE + L2 regularization\n",
    "        total_loss = mse_loss + l2_loss\n",
    "        \n",
    "        return total_loss\n",
    "\n",
    "    def backward(self, X, y_true, learning_rate=0.01):\n",
    "        # Backward propagation (Gradient Descent)\n",
    "        \n",
    "        # Output layer error and gradient\n",
    "        output_error = y_true - self.output\n",
    "        output_delta = output_error * sigmoid(self.output) * (1 - sigmoid(self.output))\n",
    "        \n",
    "        # Hidden layer error and gradient\n",
    "        hidden_error = output_delta.dot(self.weights_hidden_output.T)\n",
    "        hidden_delta = hidden_error * (self.hidden_output > 0)  # Derivative of ReLU\n",
    "        \n",
    "        # Update weights and biases (including regularization)\n",
    "        self.weights_hidden_output += self.hidden_output.T.dot(output_delta) * learning_rate\n",
    "        self.bias_output += np.sum(output_delta, axis=0, keepdims=True) * learning_rate\n",
    "        \n",
    "        self.weights_input_hidden += X.T.dot(hidden_delta) * learning_rate\n",
    "        self.bias_hidden += np.sum(hidden_delta, axis=0, keepdims=True) * learning_rate\n",
    "        \n",
    "        # L2 Regularization: update weights with the penalty term\n",
    "        self.weights_hidden_output -= self.lambda_reg * self.weights_hidden_output * learning_rate\n",
    "        self.weights_input_hidden -= self.lambda_reg * self.weights_input_hidden * learning_rate\n",
    "\n",
    "# Example usage\n",
    "input_size = 3  # Example: 3 input features\n",
    "hidden_size = 4  # Hidden layer with 4 neurons\n",
    "output_size = 1  # Output layer (1 neuron for binary classification)\n",
    "\n",
    "# Initialize the neural network with L2 regularization\n",
    "nn = NeuralNetwork(input_size, hidden_size, output_size, lambda_reg=0.01)\n",
    "\n",
    "# Example input data (3 samples, each with 3 features)\n",
    "X = np.array([[0.1, 0.2, 0.3],\n",
    "              [0.4, 0.5, 0.6],\n",
    "              [0.7, 0.8, 0.9]])\n",
    "\n",
    "# Example labels (binary classification)\n",
    "y = np.array([[0], [1], [0]])\n",
    "\n",
    "# Perform forward propagation\n",
    "output = nn.forward(X)\n",
    "print(\"Output after forward propagation:\")\n",
    "print(output)\n",
    "\n",
    "# Compute the loss including L2 regularization\n",
    "loss = nn.compute_loss(y, output)\n",
    "print(f\"Loss with L2 regularization: {loss}\")\n",
    "\n",
    "# Perform backward propagation (one training step)\n",
    "nn.backward(X, y, learning_rate=0.1)\n",
    "\n",
    "# Output after one training step\n",
    "output_after_training = nn.forward(X)\n",
    "print(\"Output after one training step:\")\n",
    "print(output_after_training)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training a Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training involves adjusting the weights and biases to minimize the loss. A popular method is gradient descent.\n",
    "\n",
    "### Exercise:\n",
    "Implement a simple gradient descent loop to train the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/1000, Loss: 0.6450537316953229\n",
      "Epoch 100/1000, Loss: 0.8349012692629962\n",
      "Epoch 200/1000, Loss: 0.8481806259881338\n",
      "Epoch 300/1000, Loss: 0.8476903050590522\n",
      "Epoch 400/1000, Loss: 0.84365146752731\n",
      "Epoch 500/1000, Loss: 0.8384385513648043\n",
      "Epoch 600/1000, Loss: 0.8328329842220306\n",
      "Epoch 700/1000, Loss: 0.8271384728051211\n",
      "Epoch 800/1000, Loss: 0.8214852566657135\n",
      "Epoch 900/1000, Loss: 0.8159317631151346\n",
      "Output after training:\n",
      "[[0.97764622]\n",
      " [0.99413874]\n",
      " [0.99847377]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sigmoid activation function with overflow prevention\n",
    "def sigmoid(x):\n",
    "    x = np.clip(x, -20, 20)  # Clamp x to prevent overflow\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Sigmoid derivative (used in backpropagation)\n",
    "def sigmoid_derivative(x):\n",
    "    sig = sigmoid(x)  # Calculate sigmoid value\n",
    "    return sig * (1 - sig)\n",
    "\n",
    "# ReLU activation function (no overflow issues)\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "# ReLU derivative (used in backpropagation)\n",
    "def relu_derivative(x):\n",
    "    return (x > 0).astype(float)\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size, lambda_reg=0.01, beta1=0.9, beta2=0.999, epsilon=1e-8):\n",
    "        # Initialize weights and biases\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.lambda_reg = lambda_reg  # Regularization strength\n",
    "        self.beta1 = beta1  # Decay rate for first moment estimate\n",
    "        self.beta2 = beta2  # Decay rate for second moment estimate\n",
    "        self.epsilon = epsilon  # Small constant for numerical stability\n",
    "        \n",
    "        # Weights and biases for each layer\n",
    "        self.weights_input_hidden = np.random.randn(self.input_size, self.hidden_size)  # Input to Hidden layer\n",
    "        self.bias_hidden = np.zeros((1, self.hidden_size))\n",
    "        \n",
    "        self.weights_hidden_output = np.random.randn(self.hidden_size, self.output_size)  # Hidden to Output layer\n",
    "        self.bias_output = np.zeros((1, self.output_size))\n",
    "        \n",
    "        # Adam optimizer variables (initialized to 0)\n",
    "        self.m_w_input_hidden = np.zeros_like(self.weights_input_hidden)\n",
    "        self.v_w_input_hidden = np.zeros_like(self.weights_input_hidden)\n",
    "        self.m_b_hidden = np.zeros_like(self.bias_hidden)\n",
    "        self.v_b_hidden = np.zeros_like(self.bias_hidden)\n",
    "\n",
    "        self.m_w_hidden_output = np.zeros_like(self.weights_hidden_output)\n",
    "        self.v_w_hidden_output = np.zeros_like(self.weights_hidden_output)\n",
    "        self.m_b_output = np.zeros_like(self.bias_output)\n",
    "        self.v_b_output = np.zeros_like(self.bias_output)\n",
    "\n",
    "    def forward(self, X):\n",
    "        # Forward propagation\n",
    "        \n",
    "        # Input to Hidden Layer\n",
    "        self.hidden_input = np.dot(X, self.weights_input_hidden) + self.bias_hidden\n",
    "        self.hidden_output = relu(self.hidden_input)  # Apply ReLU activation to hidden layer\n",
    "        \n",
    "        # Hidden to Output Layer\n",
    "        self.output_input = np.dot(self.hidden_output, self.weights_hidden_output) + self.bias_output\n",
    "        self.output = sigmoid(self.output_input)  # Apply Sigmoid activation to output layer\n",
    "        \n",
    "        return self.output\n",
    "\n",
    "    def compute_loss(self, y_true, y_pred):\n",
    "        # Mean Squared Error (MSE) loss\n",
    "        mse_loss = np.mean((y_true - y_pred) ** 2)\n",
    "        \n",
    "        # L2 Regularization term (sum of squared weights)\n",
    "        l2_loss = self.lambda_reg * (np.sum(self.weights_input_hidden ** 2) + np.sum(self.weights_hidden_output ** 2))\n",
    "        \n",
    "        # Total loss = MSE + L2 regularization\n",
    "        total_loss = mse_loss + l2_loss\n",
    "        \n",
    "        return total_loss\n",
    "\n",
    "    def backward(self, X, y_true):\n",
    "        # Backward propagation (Gradient Descent)\n",
    "        \n",
    "        # Output layer error and gradient\n",
    "        output_error = y_true - self.output\n",
    "        output_delta = output_error * sigmoid_derivative(self.output_input)\n",
    "        \n",
    "        # Hidden layer error and gradient\n",
    "        hidden_error = output_delta.dot(self.weights_hidden_output.T)\n",
    "        hidden_delta = hidden_error * relu_derivative(self.hidden_input)  # Derivative of ReLU\n",
    "        \n",
    "        # Gradients for weights and biases\n",
    "        grad_weights_hidden_output = self.hidden_output.T.dot(output_delta)\n",
    "        grad_bias_output = np.sum(output_delta, axis=0, keepdims=True)\n",
    "        \n",
    "        grad_weights_input_hidden = X.T.dot(hidden_delta)\n",
    "        grad_bias_hidden = np.sum(hidden_delta, axis=0, keepdims=True)\n",
    "        \n",
    "        # L2 Regularization: gradients for weights\n",
    "        grad_weights_hidden_output += 2 * self.lambda_reg * self.weights_hidden_output\n",
    "        grad_weights_input_hidden += 2 * self.lambda_reg * self.weights_input_hidden\n",
    "        \n",
    "        return grad_weights_input_hidden, grad_bias_hidden, grad_weights_hidden_output, grad_bias_output\n",
    "\n",
    "    def update_weights(self, grad_weights_input_hidden, grad_bias_hidden, grad_weights_hidden_output, grad_bias_output, learning_rate=0.001):\n",
    "        # Update weights using Adam optimizer\n",
    "        \n",
    "        # Update for Input to Hidden layer weights\n",
    "        self.m_w_input_hidden = self.beta1 * self.m_w_input_hidden + (1 - self.beta1) * grad_weights_input_hidden\n",
    "        self.v_w_input_hidden = self.beta2 * self.v_w_input_hidden + (1 - self.beta2) * (grad_weights_input_hidden ** 2)\n",
    "        m_w_input_hidden_hat = self.m_w_input_hidden / (1 - self.beta1)\n",
    "        v_w_input_hidden_hat = self.v_w_input_hidden / (1 - self.beta2)\n",
    "        self.weights_input_hidden -= learning_rate * m_w_input_hidden_hat / (np.sqrt(v_w_input_hidden_hat) + self.epsilon)\n",
    "\n",
    "        self.m_b_hidden = self.beta1 * self.m_b_hidden + (1 - self.beta1) * grad_bias_hidden\n",
    "        self.v_b_hidden = self.beta2 * self.v_b_hidden + (1 - self.beta2) * (grad_bias_hidden ** 2)\n",
    "        m_b_hidden_hat = self.m_b_hidden / (1 - self.beta1)\n",
    "        v_b_hidden_hat = self.v_b_hidden / (1 - self.beta2)\n",
    "        self.bias_hidden -= learning_rate * m_b_hidden_hat / (np.sqrt(v_b_hidden_hat) + self.epsilon)\n",
    "\n",
    "        # Update for Hidden to Output layer weights\n",
    "        self.m_w_hidden_output = self.beta1 * self.m_w_hidden_output + (1 - self.beta1) * grad_weights_hidden_output\n",
    "        self.v_w_hidden_output = self.beta2 * self.v_w_hidden_output + (1 - self.beta2) * (grad_weights_hidden_output ** 2)\n",
    "        m_w_hidden_output_hat = self.m_w_hidden_output / (1 - self.beta1)\n",
    "        v_w_hidden_output_hat = self.v_w_hidden_output / (1 - self.beta2)\n",
    "        self.weights_hidden_output -= learning_rate * m_w_hidden_output_hat / (np.sqrt(v_w_hidden_output_hat) + self.epsilon)\n",
    "\n",
    "        self.m_b_output = self.beta1 * self.m_b_output + (1 - self.beta1) * grad_bias_output\n",
    "        self.v_b_output = self.beta2 * self.v_b_output + (1 - self.beta2) * (grad_bias_output ** 2)\n",
    "        m_b_output_hat = self.m_b_output / (1 - self.beta1)\n",
    "        v_b_output_hat = self.v_b_output / (1 - self.beta2)\n",
    "        self.bias_output -= learning_rate * m_b_output_hat / (np.sqrt(v_b_output_hat) + self.epsilon)\n",
    "\n",
    "# Training the neural network with Adam optimizer\n",
    "def train_nn_with_adam(nn, X, y, epochs=1000, learning_rate=0.001):\n",
    "    for epoch in range(epochs):\n",
    "        # Forward pass\n",
    "        y_pred = nn.forward(X)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = nn.compute_loss(y, y_pred)\n",
    "        \n",
    "        # Backward pass (calculate gradients)\n",
    "        grad_weights_input_hidden, grad_bias_hidden, grad_weights_hidden_output, grad_bias_output = nn.backward(X, y)\n",
    "        \n",
    "        # Update weights using Adam optimizer\n",
    "        nn.update_weights(grad_weights_input_hidden, grad_bias_hidden, grad_weights_hidden_output, grad_bias_output, learning_rate)\n",
    "        \n",
    "        # Print the loss every 100 epochs\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch}/{epochs}, Loss: {loss}\")\n",
    "\n",
    "# Example usage\n",
    "input_size = 3  # Example: 3 input features\n",
    "hidden_size = 4  # Hidden layer with 4 neurons\n",
    "output_size = 1  # Output layer (1 neuron for binary classification)\n",
    "\n",
    "# Initialize the neural network with Adam optimizer\n",
    "nn = NeuralNetwork(input_size, hidden_size, output_size, lambda_reg=0.01)\n",
    "\n",
    "# Example input data (3 samples, each with 3 features)\n",
    "X = np.array([[0.1, 0.2, 0.3],\n",
    "              [0.4, 0.5, 0.6],\n",
    "              [0.7, 0.8, 0.9]])\n",
    "\n",
    "# Example labels (binary classification)\n",
    "y = np.array([[0], [1], [0]])\n",
    "\n",
    "# Train the neural network using Adam optimizer\n",
    "train_nn_with_adam(nn, X, y, epochs=1000, learning_rate=0.001)\n",
    "\n",
    "# Final output after training\n",
    "output_after_training = nn.forward(X)\n",
    "print(\"Output after training:\")\n",
    "print(output_after_training)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Adaptive Learning Rates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adaptive learning rate methods, like Adam, adjust the learning rate based on past gradients, improving training stability.\n",
    "\n",
    "### Exercise:\n",
    "Implement a simple version of the Adam optimizer for gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/1000, Loss: 0.7048434904953325\n",
      "Epoch 100/1000, Loss: 0.7825091368354644\n",
      "Epoch 200/1000, Loss: 0.8112859853070922\n",
      "Epoch 300/1000, Loss: 0.8271145124472417\n",
      "Epoch 400/1000, Loss: 0.8373385452356564\n",
      "Epoch 500/1000, Loss: 0.8446857035103422\n",
      "Epoch 600/1000, Loss: 0.8504472793517658\n",
      "Epoch 700/1000, Loss: 0.8553137178544239\n",
      "Epoch 800/1000, Loss: 0.8596818775802693\n",
      "Epoch 900/1000, Loss: 0.8637907032252363\n",
      "Output after training:\n",
      "[[0.99642696]\n",
      " [0.99982253]\n",
      " [0.99999121]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sigmoid activation function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# ReLU activation function\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size, lambda_reg=0.01, beta1=0.9, beta2=0.999, epsilon=1e-8):\n",
    "        # Initialize weights and biases\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.lambda_reg = lambda_reg  # Regularization strength\n",
    "        self.beta1 = beta1  # Decay rate for first moment estimate\n",
    "        self.beta2 = beta2  # Decay rate for second moment estimate\n",
    "        self.epsilon = epsilon  # Small constant for numerical stability\n",
    "        \n",
    "        # Weights and biases for each layer\n",
    "        self.weights_input_hidden = np.random.randn(self.input_size, self.hidden_size)  # Input to Hidden layer\n",
    "        self.bias_hidden = np.zeros((1, self.hidden_size))\n",
    "        \n",
    "        self.weights_hidden_output = np.random.randn(self.hidden_size, self.output_size)  # Hidden to Output layer\n",
    "        self.bias_output = np.zeros((1, self.output_size))\n",
    "        \n",
    "        # Adam optimizer variables (initialized to 0)\n",
    "        self.m_w_input_hidden = np.zeros_like(self.weights_input_hidden)\n",
    "        self.v_w_input_hidden = np.zeros_like(self.weights_input_hidden)\n",
    "        self.m_b_hidden = np.zeros_like(self.bias_hidden)\n",
    "        self.v_b_hidden = np.zeros_like(self.bias_hidden)\n",
    "\n",
    "        self.m_w_hidden_output = np.zeros_like(self.weights_hidden_output)\n",
    "        self.v_w_hidden_output = np.zeros_like(self.weights_hidden_output)\n",
    "        self.m_b_output = np.zeros_like(self.bias_output)\n",
    "        self.v_b_output = np.zeros_like(self.bias_output)\n",
    "\n",
    "    def forward(self, X):\n",
    "        # Forward propagation\n",
    "        \n",
    "        # Input to Hidden Layer\n",
    "        self.hidden_input = np.dot(X, self.weights_input_hidden) + self.bias_hidden\n",
    "        self.hidden_output = relu(self.hidden_input)  # Apply ReLU activation to hidden layer\n",
    "        \n",
    "        # Hidden to Output Layer\n",
    "        self.output_input = np.dot(self.hidden_output, self.weights_hidden_output) + self.bias_output\n",
    "        self.output = sigmoid(self.output_input)  # Apply Sigmoid activation to output layer\n",
    "        \n",
    "        return self.output\n",
    "\n",
    "    def compute_loss(self, y_true, y_pred):\n",
    "        # Mean Squared Error (MSE) loss\n",
    "        mse_loss = np.mean((y_true - y_pred) ** 2)\n",
    "        \n",
    "        # L2 Regularization term (sum of squared weights)\n",
    "        l2_loss = self.lambda_reg * (np.sum(self.weights_input_hidden ** 2) + np.sum(self.weights_hidden_output ** 2))\n",
    "        \n",
    "        # Total loss = MSE + L2 regularization\n",
    "        total_loss = mse_loss + l2_loss\n",
    "        \n",
    "        return total_loss\n",
    "\n",
    "    def backward(self, X, y_true):\n",
    "        # Backward propagation (Gradient Descent)\n",
    "        \n",
    "        # Output layer error and gradient\n",
    "        output_error = y_true - self.output\n",
    "        output_delta = output_error * sigmoid(self.output) * (1 - sigmoid(self.output))\n",
    "        \n",
    "        # Hidden layer error and gradient\n",
    "        hidden_error = output_delta.dot(self.weights_hidden_output.T)\n",
    "        hidden_delta = hidden_error * (self.hidden_output > 0)  # Derivative of ReLU\n",
    "        \n",
    "        # Gradients for weights and biases\n",
    "        grad_weights_hidden_output = self.hidden_output.T.dot(output_delta)\n",
    "        grad_bias_output = np.sum(output_delta, axis=0, keepdims=True)\n",
    "        \n",
    "        grad_weights_input_hidden = X.T.dot(hidden_delta)\n",
    "        grad_bias_hidden = np.sum(hidden_delta, axis=0, keepdims=True)\n",
    "        \n",
    "        # L2 Regularization: gradients for weights\n",
    "        grad_weights_hidden_output += 2 * self.lambda_reg * self.weights_hidden_output\n",
    "        grad_weights_input_hidden += 2 * self.lambda_reg * self.weights_input_hidden\n",
    "        \n",
    "        return grad_weights_input_hidden, grad_bias_hidden, grad_weights_hidden_output, grad_bias_output\n",
    "\n",
    "    def update_weights(self, grad_weights_input_hidden, grad_bias_hidden, grad_weights_hidden_output, grad_bias_output, learning_rate=0.001):\n",
    "        # Update weights using Adam optimizer\n",
    "        \n",
    "        # Update for Input to Hidden layer weights\n",
    "        self.m_w_input_hidden = self.beta1 * self.m_w_input_hidden + (1 - self.beta1) * grad_weights_input_hidden\n",
    "        self.v_w_input_hidden = self.beta2 * self.v_w_input_hidden + (1 - self.beta2) * (grad_weights_input_hidden ** 2)\n",
    "        m_w_input_hidden_hat = self.m_w_input_hidden / (1 - self.beta1)\n",
    "        v_w_input_hidden_hat = self.v_w_input_hidden / (1 - self.beta2)\n",
    "        self.weights_input_hidden -= learning_rate * m_w_input_hidden_hat / (np.sqrt(v_w_input_hidden_hat) + self.epsilon)\n",
    "\n",
    "        self.m_b_hidden = self.beta1 * self.m_b_hidden + (1 - self.beta1) * grad_bias_hidden\n",
    "        self.v_b_hidden = self.beta2 * self.v_b_hidden + (1 - self.beta2) * (grad_bias_hidden ** 2)\n",
    "        m_b_hidden_hat = self.m_b_hidden / (1 - self.beta1)\n",
    "        v_b_hidden_hat = self.v_b_hidden / (1 - self.beta2)\n",
    "        self.bias_hidden -= learning_rate * m_b_hidden_hat / (np.sqrt(v_b_hidden_hat) + self.epsilon)\n",
    "\n",
    "        # Update for Hidden to Output layer weights\n",
    "        self.m_w_hidden_output = self.beta1 * self.m_w_hidden_output + (1 - self.beta1) * grad_weights_hidden_output\n",
    "        self.v_w_hidden_output = self.beta2 * self.v_w_hidden_output + (1 - self.beta2) * (grad_weights_hidden_output ** 2)\n",
    "        m_w_hidden_output_hat = self.m_w_hidden_output / (1 - self.beta1)\n",
    "        v_w_hidden_output_hat = self.v_w_hidden_output / (1 - self.beta2)\n",
    "        self.weights_hidden_output -= learning_rate * m_w_hidden_output_hat / (np.sqrt(v_w_hidden_output_hat) + self.epsilon)\n",
    "\n",
    "        self.m_b_output = self.beta1 * self.m_b_output + (1 - self.beta1) * grad_bias_output\n",
    "        self.v_b_output = self.beta2 * self.v_b_output + (1 - self.beta2) * (grad_bias_output ** 2)\n",
    "        m_b_output_hat = self.m_b_output / (1 - self.beta1)\n",
    "        v_b_output_hat = self.v_b_output / (1 - self.beta2)\n",
    "        self.bias_output -= learning_rate * m_b_output_hat / (np.sqrt(v_b_output_hat) + self.epsilon)\n",
    "\n",
    "# Training the neural network with Adam optimizer\n",
    "def train_nn_with_adam(nn, X, y, epochs=1000, learning_rate=0.001):\n",
    "    for epoch in range(epochs):\n",
    "        # Forward pass\n",
    "        y_pred = nn.forward(X)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = nn.compute_loss(y, y_pred)\n",
    "        \n",
    "        # Backward pass (calculate gradients)\n",
    "        grad_weights_input_hidden, grad_bias_hidden, grad_weights_hidden_output, grad_bias_output = nn.backward(X, y)\n",
    "        \n",
    "        # Update weights using Adam optimizer\n",
    "        nn.update_weights(grad_weights_input_hidden, grad_bias_hidden, grad_weights_hidden_output, grad_bias_output, learning_rate)\n",
    "        \n",
    "        # Print the loss every 100 epochs\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch}/{epochs}, Loss: {loss}\")\n",
    "\n",
    "# Example usage\n",
    "input_size = 3  # Example: 3 input features\n",
    "hidden_size = 4  # Hidden layer with 4 neurons\n",
    "output_size = 1  # Output layer (1 neuron for binary classification)\n",
    "\n",
    "# Initialize the neural network with Adam optimizer\n",
    "nn = NeuralNetwork(input_size, hidden_size, output_size, lambda_reg=0.01)\n",
    "\n",
    "# Example input data (3 samples, each with 3 features)\n",
    "X = np.array([[0.1, 0.2, 0.3],\n",
    "              [0.4, 0.5, 0.6],\n",
    "              [0.7, 0.8, 0.9]])\n",
    "\n",
    "# Example labels (binary classification)\n",
    "y = np.array([[0], [1], [0]])\n",
    "\n",
    "# Train the neural network using Adam optimizer\n",
    "train_nn_with_adam(nn, X, y, epochs=1000, learning_rate=0.001)\n",
    "\n",
    "# Final output after training\n",
    "output_after_training = nn.forward(X)\n",
    "print(\"Output after training:\")\n",
    "print(output_after_training)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
